{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4\n",
    "## Monte Carlo Eksperimenter\n",
    "\n",
    "I ugeseddel 4 skal I arbejde med et simulationsstudie, hvor I skal undersøge og sammenligne en simpel og multipel OLS estimator i et tilfælde med udeladt variabelbias. Generelt kan I bruge Monte Carlo eksperimenter til at opstille en model, hvor I kan kontrollere alle aspekter af den, undersøge egenskaber ved en estimator, f.eks. hvis MLR.1 til MLR.4 ikke er opfyldt, eller hvis I ønsker at undersøge en ny estimator eller undersøge asymptotiske resultater.\n",
    "\n",
    "I denne ugeseddel skal I se nærmere på følgende datagenererende proces (DGP): \n",
    "\n",
    "\\begin{align}\n",
    "y_i &= \\beta_0 + \\beta_1 x_{1i} +\\beta_2 x_{2i}+ u_i, \\\\\n",
    "\\beta_0 &= 1,\\, \\beta_1 = 2, \\beta_2=-3, \\\\\n",
    "x_1 &\\sim N(25,25),\\, u\\sim U(-50,50), \\, \\, x_2^*\\sim U(10,30) \\\\\n",
    "x_2 &= \\rho x_1 + x_2^*, \\, \\rho=0.5, \\, n=50\n",
    "\\end{align}\n",
    "\n",
    "Den datagenerende proces specificerer de sande værdier af $\\beta_0$, $\\beta_1$ og $\\beta_2$ samt fordelingerne af $x_1$, $x_2$ og $u$. I dette tilfælde viser ligning (2) de sande parameterværdier, ligning (3) viser hvilken fordeling $x_1$, $x_2^*$ og $u$ er trukket fra, og ligning (1) viser sammenhængen imellem dem i en lineær regression. Ligning (4) viser, at $x_2$ er en lineær funktion af de stokastiske variable $x_1$ og $x_2^*$, hvor $\\rho$ angiver hvor meget $x_2$ afhænger af $x_1$.\n",
    "\n",
    "I skal undersøge og sammenligne egenskaberne for OLS estimatoren i en simpel og multipel regressionsmodel. Nedenfor er udtrykket for OLS estimatoren for $\\beta_1$ i det simple tilfælde, $\\widetilde{\\beta}_1$, og i et tilfælde med flere forklarende variable, $\\widehat{\\beta}_1$.\n",
    "\n",
    "\\begin{align} \\tag{5}\n",
    "\\widetilde{\\beta }_{1}& =\\frac{\\sum_{i}(x_{i1}-\\bar{x}_{1})(y_{i}-\\bar{y})}{%\n",
    "\\sum_{i}(x_{i1}-\\bar{x}_{1})^{2}} \\\\[8pt]\n",
    "\\widehat{\\beta }& =\\left( \n",
    "\\begin{array}{c} \\tag{6}\n",
    "\\widehat{\\beta }_{0} \\\\ \n",
    "\\widehat{\\beta }_{1} \\\\ \n",
    "\\widehat{\\beta }_{2}%\n",
    "\\end{array}%\n",
    "\\right) =(X^{\\prime }X)^{-1}X^{\\prime }y\n",
    "\\end{align}%\n",
    "hvor $X$ i ligning (6) indeholder information om $x_{1}$, $x_{2}$ og en konstant. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gruppespørgsmål"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opgave 1:** Forventer I en positiv eller negativ bias, når I estimerer en simpel model kun med $x_1$? Hvad er størrelsen på den asymptotiske bias? Beregn dette (brug pen og papir).\n",
    "\n",
    "[Anvend følgende udtryk for asymptotisk bias, hvor $\\widetilde{u}=\\beta_2x_2 + u$]\n",
    "\\begin{align*}\n",
    "p\\text{lim}(\\widetilde{\\beta}_1)-\\beta_1 = \\frac{\\text{Cov}(x_1,\\widetilde{u})}{%\n",
    "\\text{Var}(x_1)}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vi forventer et negativt bias i en simpel model kun med $x_1$. Tag udgangspunkt i tabel 3.2 i Wooldridge. Her kan vi se, at når $\\beta_2<0$ og $\\text{corr}(x_1,x_2)>0$, så vil bias være negativt.  Når vi beregner størrelsen af de asymptotiske bias, tager vi udgangspunkt i ligningen i gruppespørgsmålet:\n",
    "> \n",
    "> \\begin{align*}\n",
    "> p\\text{lim}(\\widetilde{\\beta}_1)-\\beta_1 &= \\frac{cov(x_1,\\widetilde{u})}{var(x_1)} = \\frac{cov(x_1,\\beta_2x_2+u)}{var(x_1)} = \\frac{\\beta_2\\cdot cov(x_1,\\rho x_1+x_2^*) + cov(x_1,u)}{var(x_1)} \\\\\n",
    "> &= \\frac{\\beta_2\\rho \\cdot var(x_1) + \\beta_2\\cdot cov(x_1,x_2^*)}{var(x_1)} = \\frac{\\beta_2\\rho \\cdot var(x_1)}{var(x_1)} = \\beta_2\\rho\n",
    "> \\end{align*}\n",
    "> \n",
    "> Hvis vi indsætter værdierne fra ligning (2) og (4) får vi, at bias vil være $\\beta_2\\rho = -3\\cdot 0.5 = -1.5$.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opgave 2:** Opfylder den datagenererende proces MLR.1 til MLR.4? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Den datagenererende proces opfylder MLR.1-MLR.4. \n",
    "> \n",
    "> MLR.1: Lineær i parametrene er opfyldt i ligning (1). \n",
    "> \n",
    "> MLR.2: Tilfældig udvælgelse sker, når numpy trækker tilfældige tal ud fra de relevante fordelinger. \n",
    "> \n",
    "> MLR.3: Inge perfekt multikolinearitet, bemærk, at det gælder selvom $x_1$ og $x_2$ er korreleret. \n",
    "> \n",
    "> ML.4: Eksogenitet, $E(u|X)=0$, herunder er $E(u) = \\frac{a+b}{2} = \\frac{-50+50}{2}=0$. \n",
    "> \n",
    "> Når MLR.1-MLR.4 er opfyldt, er estimatoren middelret.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opgave 3:** Hvordan kan et Monte Carlo-eksperiment blive brugt til at sammenligne variansen fra to forskellige middelrette estimatorer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Et Monte Carlo eksperiment kan blive brugt til at sammenligne variansen fra forskellige middelrette estimatorer, fordi vi udregner de to estimatorer på samme tilfældige udtrækninger. I et sådan tilfælde vil estimatoren med den mindste varians være at foretrække."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python øvelser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 1\n",
    "\n",
    "I skal starte med at opstille Monte Carlo eksperimentet i Python. I skal udfylde den del af Python-koden, som mangler. I skal først køre Monte Carlo eksperimentet, når I har skrevet al koden ind. Der skal udfyldes manglende kode i hvert af de fire steps angivet i kommentarerne til funktionen herunder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "\n",
    "\t## Step 1. Definer parameterværdier\n",
    "\tn = 50\n",
    "\trho = 0.5\n",
    "\tbeta0 = 1\n",
    "\tbeta1 = 2\n",
    "\tbeta2 = -3\n",
    "\n",
    "\t# Step 2. Simular data\n",
    "\tx1 = np.random.normal(loc=25, scale=5, size=n) # Trækker x1 fra normalfordeling\n",
    "\tu  = np.random.uniform(low=-50, high=50, size=n) # Trækker u fra uniformfordeling\n",
    "\tx2_star = np.random.uniform(low=10, high=30, size=n) # Trækker x2* fra uniformfordeling\n",
    "\tx2 = rho*x1 + x2_star\n",
    "\ty = beta0 + beta1*x1 + beta2*x2 + u\n",
    "\n",
    "\t## Step 3: Estimer SLR modellen (y ~ x1)\n",
    "\tX = pd.DataFrame({'x1': x1}) \n",
    "\tX = sm.add_constant(X)\n",
    "\tSLR_model = sm.OLS(y, X)\n",
    "\tSLR_results = SLR_model.fit()\n",
    "\tbeta1_SLR = SLR_results.params['x1'] # Gemmer beta1 fra SLR-estimatet\n",
    "\n",
    "\t# Step 4: Estimer MLR modellen (y ~ x1 + x2)\n",
    "\tX = pd.DataFrame({'x1': x1, 'x2': x2})\n",
    "\tX = sm.add_constant(X)\n",
    "\tMLR_model = sm.OLS(y, X)\n",
    "\tMLR_results = MLR_model.fit()\n",
    "\tbeta1_MLR = MLR_results.params['x1'] # Gemmer beta1 fra MLR-estimatet\n",
    "\n",
    "\treturn beta1_SLR, beta1_MLR\n",
    "\n",
    "\n",
    "def monte_carlo(reps=1000):\n",
    "\tnp.random.seed(0) # Sæt seed så vi får samme tilfældige resultater hver gang\n",
    "\tSLR_results = [] # Liste til at gemme beta1 resultater fra SLR\n",
    "\tMLR_results = [] # Liste til at gemme beta1 resultater fra MLR\n",
    "\n",
    "\tfor rep in range(reps): # Kør simulationen \"reps\" antal gange\n",
    "\t\tbeta1_MLR, beta1_SLR = simulate()\n",
    "\t\tSLR_results.append(beta1_MLR)\n",
    "\t\tMLR_results.append(beta1_SLR)\n",
    "\n",
    "\tresults = pd.DataFrame({'beta1_SLR': SLR_results, 'beta1_MLR': MLR_results})\n",
    "\n",
    "\treturn results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kør simulationen og gem resultaterne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = monte_carlo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 2 \n",
    "Sammenlign $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$. Stemmer resultaterne overens med det, som I fandt i gruppespørgsmål 1? I kan bruge `.describe()` til at se gennemsnittet og variansen af $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$ fra eksperimentet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Din kode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta1_SLR</th>\n",
       "      <th>beta1_MLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.557254</td>\n",
       "      <td>2.053022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.949422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.519445</td>\n",
       "      <td>-0.955532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.110461</td>\n",
       "      <td>1.409247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.550903</td>\n",
       "      <td>2.064756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.231652</td>\n",
       "      <td>2.677015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.314772</td>\n",
       "      <td>5.022302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beta1_SLR    beta1_MLR\n",
       "count  1000.000000  1000.000000\n",
       "mean      0.557254     2.053022\n",
       "std       0.998867     0.949422\n",
       "min      -2.519445    -0.955532\n",
       "25%      -0.110461     1.409247\n",
       "50%       0.550903     2.064756\n",
       "75%       1.231652     2.677015\n",
       "max       4.314772     5.022302"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vi får at $\\widetilde{\\beta}_1 \\approx 0.5$ og $\\hat{\\beta}_1\\approx 2$. Det er, hvad vi forventer ud fra gruppespørgsmål 1, om en negativ bias på $-1.5$ i den simple model kun med $x_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 3\n",
    "Kør et Monte Carlo eksperiment med $n=10$ og $n=100$. Sammenlign $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$. Er både $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$ konsistente estimatorer for $\\beta_1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Når $n=10$ og $n=100$ får vi approksimativt de samme estimater for $\\widetilde{\\beta}_1$ og $\\hat{\\beta}_1$ som ovenfor. Her er det i stedet interessant at se på variansen i de to simulationer. Når $n=10$ er variansen $\\approx 2.5$, imens variansen er $\\approx 0.65$, når $n=100$. Der er mindre variation i estimaterne, hvis der er flere observationer med i hver simulation. $\\hat{\\beta}_1$ er middelret i begge tilfælde, men estimaterne af $\\hat{\\beta}_1$ koncentreres mere om den sande værdi, når antallet af observationer øges. Flere observationer i hver simulation ændrer ikke på, at $\\widetilde{\\beta}_1$ fortsat ikke er middelret. Det er ikke muligt at fjerne en asymptotisk bias ved at øge antallet af observationer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 4\n",
    "Kør er Monte Carlo eksperiment med $\\rho=1$ og $\\rho=0$ (og $n = 50$). Er multikolinearitet et problem, når $\\rho = 1$? Bliver den asymptotiske bias større eller mindre? Hvis den gør, hvorfor er det tilfældet? Hvilken forskel er der i variansen af $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$, når $\\rho = 0$? Hvilken estimator vil I foretrække?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Når $\\rho = 1$ bliver den negative bias i $\\widetilde{\\beta}_1$ større. Det bliver $\\beta_2\\rho = -3\\cdot 1  = -3$. Perfekt multikolinearitet er ikke et problem, da $x_2$ forsat afhænger af $x_2^*$. Når korrelationen mellem $x_1$ og $x_2$ øges, bliver det sværere at estimere effekten af $x_1$ i en multipel regressionsmodel. Dette kan ses på den større varians af $\\hat{\\beta}_1$. Når $\\rho=0$ forsvinder bias i $\\widetilde{\\beta}_1$. Variansen af $\\widetilde{\\beta}_1$ er større end variansen af $\\hat{\\beta}_1$, fordi fejlledet i den simple model indeholder $\\beta_2x_2$. Derfor foretrækkes den multiple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 5\n",
    "Kør et Monte Carlo eksperiment med $\\rho=0.5$ og $\\beta_2=0$. Sammenlign $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$. Hvilken er estimator vil I foretrække i dette tilfælde?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Når $\\beta_2 = 0$ forsvinder bias i $\\widetilde{\\beta}_1$. Modsat spørgsmål 4 er $\\widetilde{\\beta}_1$ den foretrukne estimator, da det aldrig bør være muligt at få en mere efficient estimator ved at inkludere irrelevante variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 6\n",
    "Kør det oprindelige Monte Carlo eksperiment med et andet seed-nummer. I kan f.eks. sætte seed-nummeret til det år, I er født. Hvad kan I konkludere om $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$ ud fra denne ændring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Det ændrer intet ved estimaterne af $\\widetilde{\\beta}_1$ og $\\hat{\\beta}_1$ at ændre seed-nummeret. Dette nummer angiver kun, hvor numpy skal begynde at udtrække tilfældige tal, så de samme tilfældige tal bliver trukket hver gang.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstraopgave: \n",
    "Hvis I har mere tid tilbage, kan I lave histogrammer af  $\\widetilde{\\beta}_1$ og $\\widehat{\\beta}_1$  for hver ændring i Monte Carlo eksperimentet fra spørgsmål 2 til 6. I kan bruge koden nedenfor. Husk at gemme histogrammerne efter hver simulation, hvis I gerne vil sammenligne med det oprindelige eksperiment.\n",
    "\n",
    "```py\n",
    "import seaborn as sns\n",
    "sns.histplot(results);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Din kode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(results);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
